{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cloning the Repository**  \n",
    "\n",
    "To get started, clone the repository using the following command:  \n",
    "\n",
    "```bash\n",
    "git clone https://github.com/atikul-islam-sajib/tinyMultiModalClassifier.git\n",
    "```\n",
    "\n",
    "This will download the complete project to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/atikul-islam-sajib/tinyMultiModalClassifier.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Change Directory to the Repository**  \n",
    "\n",
    "Before running any scripts, navigate to the cloned repository directory:\n",
    "\n",
    "```bash\n",
    "%cd tinyMultiModalClassifier\n",
    "```\n",
    "\n",
    "### **Why This Step?**  \n",
    "- Ensures all paths and dependencies are correctly referenced.  \n",
    "- Allows seamless execution of training, testing, and configuration scripts.  \n",
    "- Prevents file path issues when accessing datasets and models.  \n",
    "\n",
    "Make sure you have cloned the repository before running this command! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd tinyMultiModalClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Installing Dependencies**  \n",
    "\n",
    "To install all required dependencies, run the following command:  \n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This will ensure that all necessary packages are installed for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Configuring `config.yml` File**  \n",
    "\n",
    "The `config.yml` file contains all essential configurations for data paths, model parameters, training settings, and evaluation. Ensure that these parameters are properly set before running the project.\n",
    "\n",
    "---\n",
    "\n",
    "### **Artifacts & Paths**  \n",
    "Define the directories where raw, processed data, model checkpoints, and outputs are stored.\n",
    "\n",
    "```yaml\n",
    "artifacts:\n",
    "    raw_data_path: \"./data/raw/\"\n",
    "    processed_data_path: \"./data/processed/\"\n",
    "    checkpoints: \"./artifacts/checkpoints/\"\n",
    "    train_models: \"./artifacts/checkpoints/train_models/\"\n",
    "    best_model: \"./artifacts/checkpoints/best_model/\"\n",
    "    files: \"./artifacts/files/\"\n",
    "    metrics: \"./artifacts/metrics/\"\n",
    "    train_images: \"./artifacts/outputs/train_images/\"\n",
    "    val_images: \"./artifacts/outputs/val_images/\"\n",
    "    test_image: \"./artifacts/outputs/test_image/\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Patch Embeddings Configuration**  \n",
    "Defines the patch size and embedding dimensions for image processing.\n",
    "\n",
    "```yaml\n",
    "patchEmbeddings:\n",
    "    channels: 3                  # Number of image channels (RGB)\n",
    "    patch_size: 16               # Size of each patch\n",
    "    image_size: 224              # Input image resolution\n",
    "    dimension: 256               # Embedding dimension\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Transformer Encoder Block Settings**  \n",
    "Defines the architecture parameters for the transformer encoder block.\n",
    "\n",
    "```yaml\n",
    "transfomerEncoderBlock:\n",
    "    nheads: 8                         # Number of attention heads\n",
    "    activation: \"relu\"                # Activation function(\"leaky\", \"relu\", \"selu\", \"gelu\")\n",
    "    dropout: 0.1                      # Dropout rate\n",
    "    num_encoder_layers: 6             # Number of transformer encoder layers\n",
    "    dimension_feedforward: 4096       # Hidden layer size in feedforward network\n",
    "    layer_norm_eps: 1e-5              # Epsilon value for layer normalization\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Dataloader Settings**  \n",
    "Configuration for dataset path, batch size, and dataset split ratio.\n",
    "\n",
    "```yaml\n",
    "dataloader:\n",
    "    dataset: \"./raw/image_dataset.zip\"    # Path to the dataset\n",
    "    batch_size: 32                        # Number of samples per batch\n",
    "    split_size: 0.30                      # Train-validation split ratio\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Training Configuration**  \n",
    "Defines hyperparameters and settings for model training.\n",
    "\n",
    "```yaml\n",
    "trainer:\n",
    "    model: None                       # Model type (None if training from scratch)\n",
    "    epochs: 200                       # Number of training epochs\n",
    "    lr: 2e-4                          # Learning rate\n",
    "    weight_decay: 5e-4                # Weight decay for regularization\n",
    "    beta1: 0.9                        # Beta1 for Adam optimizer\n",
    "    beta2: 0.999                      # Beta2 for Adam optimizer\n",
    "    momentum: 0.95                    # Momentum (for SGD optimizer)\n",
    "    lr_scheduler: False               # Enable learning rate scheduler\n",
    "    step_size: 20                     # Step size for learning rate decay\n",
    "    gamma: 0.1                        # Learning rate decay factor\n",
    "    l1_regularization: False          # Enable L1 regularization\n",
    "    l2_regularization: False          # Enable L2 regularization\n",
    "    l1_lambda: 0.0                    # L1 regularization weight\n",
    "    l2_lambda: 0.0                    # L2 regularization weight\n",
    "    adam: True                        # Use Adam optimizer\n",
    "    SGD: False                        # Use SGD optimizer\n",
    "    mlflow: False                     # Enable MLFlow tracking\n",
    "    verbose: False                    # Enable verbose training output\n",
    "    device: \"cuda\"                    # Device to use for training (cpu, cuda, mps)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Testing Configuration**  \n",
    "Settings for evaluating the trained model.\n",
    "\n",
    "```yaml\n",
    "tester:\n",
    "    model: \"best\"                       # Model to use for testing (best or latest)\n",
    "    device: \"cuda\"                      # Device for testing (cpu, cuda, mps)\n",
    "    plot_images: True                   # Enable image visualization during testing\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Final Notes**  \n",
    "- Ensure that all paths and parameters are correctly configured before running the project.  \n",
    "- Modify the values based on your dataset and computing resources.  \n",
    "- Adjust optimizer and regularization settings based on your training goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cat config.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training the Model**  \n",
    "\n",
    "To train the **Tiny Multi-Modal Classifier**, execute the following command:\n",
    "\n",
    "```bash\n",
    "!python src/cli.py --train\n",
    "```\n",
    "\n",
    "### **Description**  \n",
    "- **`--train`**: This flag initiates the training process based on the configurations specified in `config.yml`.\n",
    "\n",
    "### **Training Workflow**  \n",
    "1. **Loads Dataset** â†’ Reads and preprocesses the dataset.  \n",
    "2. **Model Initialization** â†’ Builds the model using the defined architecture.  \n",
    "3. **Training Loop** â†’ Runs multiple epochs, optimizing loss and accuracy.  \n",
    "4. **Checkpointing** â†’ Saves the best-performing model for future use.  \n",
    "5. **Logs and Metrics** â†’ Tracks training progress and logs key metrics.  \n",
    "\n",
    "Make sure your dataset and configurations are properly set before running the command! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /src/cli.py --train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing the Model**  \n",
    "\n",
    "To evaluate the **Tiny Multi-Modal Classifier**, run the following command:\n",
    "\n",
    "```bash\n",
    "!python src/cli.py --test\n",
    "```\n",
    "\n",
    "### **Description**  \n",
    "- **`--test`**: This flag initiates the model evaluation using the test dataset.\n",
    "\n",
    "### **Testing Workflow**  \n",
    "1. **Loads Pretrained Model** â†’ Loads the best or specified model from checkpoints.  \n",
    "2. **Processes Test Data** â†’ Prepares the dataset for inference.  \n",
    "3. **Performs Inference** â†’ Generates predictions on the test dataset.  \n",
    "4. **Computes Metrics** â†’ Evaluates accuracy, loss, and other key metrics.  \n",
    "5. **Visualizes Results** â†’ Optionally, plots predictions and ground truth images.  \n",
    "\n",
    "Ensure the trained model is available in the checkpoints before running the test! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/cli.py --test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
